
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Xception??? Pytorch??}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{이제는 기본 모델이 된 'Xception'
이해하기!}\label{uxc774uxc81cuxb294-uxae30uxbcf8-uxbaa8uxb378uxc774-uxb41c-xception-uxc774uxd574uxd558uxae30}

Pretrained 된 모델을 사용하거나 Transfer Learning 을 사용하는 모델들에
대해서 읽을 때 Backbone (척추같은 존재 \textsuperscript{0})가 되는 CNN
모델들이 몇 개 있습니다. VGG family, ResNet family, Inception family,
그리고 Xception. 더 복잡한 작업(e.g. Semantic Segmentation 등)의 기초가
되는 이 네트워크, 특히 Xception, 에 대해서 제대로 알아야겠다는 생각이
들어서 정리해보았습니다.

\subsubsection{목차}\label{uxbaa9uxcc28}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Xception 의 바탕이 되는 'Inception Family' 정리
\item
  Xception 의 핵심 포인트, Modified Depthwise Separable Convolution
  이해하기
\item
  Overall Architecture
\item
  Pytorch 로 구현해보는 Xception
\end{enumerate}

    \subsubsection{0. Xception
모델이란?}\label{xception-uxbaa8uxb378uxc774uxb780}

Xception 은 구글이 2017년에 발표한 모델로, 2015년에 ILSVRC 대회에서
2등을 한 Google 의 Inception-V3 모델보다 훨씬 좋은 결과를 냈습니다. -
Encoder-Decoder 형태의 모델들에서 pretrain 된 Xception 모델이 Encoder로
자주 쓰입니다. 또한 Xception 에서 제시하는 모델의 구조나 핵심인
'modified depthwise separable convolution'의 개념이 간단하기 때문에 다른
모델에도 적용하기 쉽습니다. - Xception 이라는 이름 자체가 Extreme +
Inception 에서 나온 만큼 Inception 모델이 기본이 된다는 것을 알 수
있으니까, 먼저 Inception 모델들에 대해서 간단하게 정리하겠습니다.

    \subsubsection{1. Inception Family 의 포인트
정리}\label{inception-family-uxc758-uxd3ecuxc778uxd2b8-uxc815uxb9ac}

Inception 모델은 지금까지 version 4과 ResNet이 합쳐진 Inception-ResNet
v2 까지 나왔습니다. 각 모델에 대한 설명은
https://norman3.github.io/papers/docs/google\_inception.html 여기를
참고하면 자세한 정보를 얻으실 수 있습니다.

맛보기로 Inception-ResNet V2의 Architecture 입니다:

다른 모델에 활용하기에는 복잡해서 연산량이나 parameter의 개수가 VGG보다
훨씬 적음에도 불구하고 vgg net이 더 자주 사용된다고하네요 :(

** - Inception 모델의 목적? **

딥러닝은 망이 깊을수록 (deep), 레이어가 넓을수록 (wide) 성능이 좋지만,
overfitting \& vanishing gradient 의 문제로 깊고 넓게만 모델을 만드는
것은 문제가 됩니다. Inception 은 Convolution 레이어를 sparse 하게
연결하면서 행렬 연산은 dense하게 처리하기 위해 고안한 모델입니다.

** - 다른 Convolution과 어떻게 다른가? **

보통 5x5 또는 7x7의 하나의 convolution 필터로 진행하는데, Inception
모델에서는 conv 레이어 여러 개를 한 층에서 구성하는 형태를 취하고
있습니다.\\
영화 Inception 에서 이름을 따온 이유가 여기 있습니다! '동시에' (같은
Layer에서) 다양한 convolution 을 진행하기 때문이죠

\begin{itemize}
\tightlist
\item
  왜 굳이 귀찮게 하는가? Parameter 의 개수도 줄이고, 연산량도 줄일 수
  있기 때문!
\item
  Kernel size가 늘어날수록 연산량의 크기가 굉장히 커지기 때문에 나중에는
  5x5 가 아니라 3x3을 2번 하는 방향으로 바뀝니다 -\textgreater{} 더
  나아가서 3x3 를 쪼개서 3x1 과 1x3 convolution 을 2번하는 방향으로
  가기도 합니다 (Asymmetric Convolution Factorizing 이라고 부릅니다)
\end{itemize}

** - 1x1 Convolution 을 하는 이유? **

Convolution의 연산은 {[}Batch Size, Width, Height, Channel{]}, 4차원의
데이터로 표기합니다. 보통의 convolution 은 채널의 개수를 늘리지만,1x1
연산의 목적은 채널의 개수를 줄여서 압축하는데에 있습니다.

** - Residual Network 를 사용하면 좋은 점? **

위 그래프와 같이 학습 수렴 속도가 빨라집니다.

\begin{itemize}
\tightlist
\item
  잠깐 복습! Residual Net 이란?
\end{itemize}

왼쪽: 가장 간단한 형태의 residual-connection \textbar{} 오른쪽: 1 x 1
conv 를 추가해서 연산량을 줄인 모델

ResNet 은 간단하게 얘기하면: 몇 단계 전 레이어의 결과를 현재 레이어의
결과와 합쳐 내보내는 네트워크입니다.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\begin{verbatim}
    즉, 정리하자면 'Inception' 모델들의 내용은: 
\end{verbatim}

A. Convolution 을 할 때 하나의 큰 kernel 을 사용할게 아니라 다양한
크기를 이어붙이는것이 연산량 \& parameter의 개수도 적도, 좋은 결과를
얻을 수 있다!

B. 거기에 ResNet 넣으면 수렴속도도 빨라지고

C. 하는김에 Factorization 까지 하면 더 연산량도 줄고

-\/-\textgreater{} 어떻게 Inception module 을 구성하느냐에 따라 버젼이
바뀝니다.

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{오늘의 주제, Xception
모델!}\label{uxc624uxb298uxc758-uxc8fcuxc81c-xception-uxbaa8uxb378}

\begin{itemize}
\tightlist
\item
  Xception의 중점 포인트: \textbf{Modified Depthwise Separable
  Convolution}

  \begin{itemize}
  \tightlist
  \item
    오리지널 Depthwise Separable Convolution 이란?
  \item
    Modified? 뭐가 바뀌었나?
  \end{itemize}
\item
  Xception 의 목적? 연산량과 parameter의 개수를 줄여서, 큰 이미지 인식을
  고속화 시키자!
\end{itemize}

장점: VGG처럼 네트워크의 구조가 간단해서 (inception 과 달리..) 활용도가
높다!

\begin{itemize}
\tightlist
\item
  논문에서 얘기하는 Xception 의 바탕이 된 개념들
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  VGG16의 구조: Deep 하게 쌓아가는 구조를 따온 점!
\item
  Inception Family: Conv 를 할 때 몇개의 branch 로 factorize 해서
  진행하는 것의 장점을 알려준 점!
\item
  Depthwise Separable Convolution: 가장 중요한 개념! 네트워크의 사이즈와
  연산량을 줄이기 위한 연구 (채널별로 conv 를 진행한 후 space 에 대해서
  conv 를 진행한다)
\end{enumerate}

    \subsubsection{2. Modified Depthwise Separable
Convolution}\label{modified-depthwise-separable-convolution}

\paragraph{1) 일단, 원조 'Depthwise Separable Convolution'은
무엇인가?}\label{uxc77cuxb2e8-uxc6d0uxc870-depthwise-separable-convolutionuxc740-uxbb34uxc5c7uxc778uxac00}

Depthwise(깊이 별로 == 채널 별로) Separable(나누어서) convolution 을
하는 것! 일반 Convolution과 결과는 같지만 두 단계로 진행됩니다.

** 1단계: Channel-wise nxn spatial convolution **

위에 그림에서와 같이 인풋으로 5개의 채널이 들어오면 5개의 n x n
convolution 을 따로 진행해서 합칩니다.

** 2단계: Pointwise Convolution **

원래 우리가 알고있는 1x1 convolution입니다. 채널의 개수를 줄이기 위한
방법으로 사용됩니다.

예시: 밑에와 같이 256 x 256 x 3 의 인풋이 있을 때

1단계에서는: 256 x 256 x 1 을 3번 진행해서 concat을 합니다

2단계에서는: pointwise convolution을 이용해서 채널의 개수를 1개로
줄입니다! (단순하게 weighted sum 을 계산하는 것)

\begin{itemize}
\tightlist
\item
  결과적으로는 같은데, 왜 굳이 2단계로 나눠서 하는가? 위와같은 과정으로
  Convolution 을 하면 약 9배 정도 빠르다고 합니다.
\end{itemize}

일반 convolution 의 계산량 - 특징 맵의 크기: F x F - 입력 채널 수: N -
커널 크기: K x K - 출력 채널 수: M - 계산량 F x F x N x K x K x M -
Parameter 수: K x K x N x M

Point-wise 의 계산량 - 같은 크기의 아웃풋을 만들어 낸다 - 특징 맵의
차원을 늘리거나 줄일 때 사용된다 - K = 1 으로 만든 것. - 계산량은 F x F
x N x M - Parameter 수: N x M Depthwise: 특징맵 채널마다 각각 공간
방향의 convolution 을 한다 - 채널방향으로 수행하지 않기 때문에 일반
convolution 1회의 cost -\textgreater{} K x K - 계산량: F x F x N x K x K
- Parameter: K x K x N

결론: 계산량: FxFxNxKxKxM -\/-\textgreater{} FxFxNxM + FxFxNxKxK로 감소

즉, 1/K\^{}2 + 1/M 으로 됩니다-\/-\textgreater{} 보통 M
\textgreater{}\textgreater{} K\^{}2 이므로 계산량은 1/9정도가 됩니다

\subparagraph{2) Xception 의 'Modified' 는 뭐가
달라졌는가?}\label{xception-uxc758-modified-uxb294-uxbb50uxac00-uxb2ecuxb77cuxc84cuxb294uxac00}

\begin{itemize}
\item
  연산의 순서: 원래는 depthwise 를 진행하고, pointwise 를 했는데, 이제는
  pointwise -\textgreater{} depthwise 로 바꿈
\item
  Non-Linearity 의 유무: Inception 모델의 경우, 첫 연산 후에
  non-linearity (ReLU)가 있지만, Xception은 중간에 ReLU non-linearity 를
  적용하지 않는다
\item
  Residual connection 이 거의 모든 Layer 에 있다 -\textgreater{} 없애고
  실험해봤더니 있을때의 정확도가 훨씬 높았음. residual connection 이
  굉장히 중요한 요소임
\end{itemize}

구조 자체는 굉장히 간단해서 밑에 있는 사진을 보면 쉽게 이해가 갑니다.

    \subsubsection{Overall Architecture}\label{overall-architecture}

Entry, Middle, Exit의 3개 구조로 나뉩니다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Entry Flow
\end{enumerate}

\begin{itemize}
\tightlist
\item
  인풋: 229 x 229 x 3
\item
  모든 convolutional layer 다음에는 batch normalization 을 사용한다
\item
  2번 normal convolution (3x3) -\textgreater{} 필터의 갯수: 32
  -\textgreater{} 64
\item
  Residual Network 가 합쳐진 Inception Module 3번
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Middle Flow
\end{enumerate}

\begin{itemize}
\tightlist
\item
  반복되는 단순한 모델: 필터의 개수와 width/height 는 바뀌지 않는다
\item
  ReLU -\textgreater{} Separable Conv -\textgreater{} Separable Conv
  이걸 8번 반복하기
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Exit Flow
\end{enumerate}

\begin{itemize}
\tightlist
\item
  filter의 개수를 늘린다음 -\textgreater{} Maxpooling -\textgreater{}
  2번 separable convolution -\textgreater{} Global Average Pooling
  -\textgreater{} Optional Fully-Connected -\textgreater{} Logistic
  Regression
\end{itemize}

    \subsection{Pytorch 로
구현해보기!}\label{pytorch-uxb85c-uxad6cuxd604uxd574uxbcf4uxae30}

위 코드는 https://github.com/tstandley/Xception-PyTorch 위 깃헙에서
대부분을 가져왔습니다!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k+kn}{import} \PY{n+nn}{torch}
        \PY{k+kn}{import} \PY{n+nn}{math} 
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn}\PY{n+nn}{.}\PY{n+nn}{functional} \PY{k}{as} \PY{n+nn}{f} 
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}zoo} \PY{k}{as} \PY{n+nn}{model\PYZus{}zoo}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{import} \PY{n}{init} 
        
        \PY{c+c1}{\PYZsh{} Pretrained 된 weight 를 사용할 때 필요합니다. weight 들이 담긴 파일을 다운받는 링크입니다}
        \PY{n}{model\PYZus{}urls} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{xception}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{https://www.dropbox.com/s/1hplpzet9d7dv29/xception\PYZhy{}c0a72b38.pth.tar?dl=1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
\end{Verbatim}


    모델에서 기본으로 사용되는 'Convolution' -\textgreater{} 'Pointwise
Convolution' 을 하나의 class 로 묶어서 재사용할 수 있게 합니다.

사진에 있는 빨간 동그라미 하나를 만드는 것! 

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{class} \PY{n+nc}{SeparableConv2d}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
          \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{in\PYZus{}channels}\PY{p}{,} \PY{n}{out\PYZus{}channels}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{padding} \PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{dilation}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{}nn.Module 을 상속받게 만들기 }
            \PY{n+nb}{super}\PY{p}{(}\PY{n}{SeparableConv2d}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}Forward 에서 쓸 함수들을 정의해주기}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{n}{in\PYZus{}channels} \PY{o}{=} \PY{n}{in\PYZus{}channels}\PY{p}{,} 
                                  \PY{n}{out\PYZus{}channels} \PY{o}{=} \PY{n}{in\PYZus{}channels}\PY{p}{,} \PY{c+c1}{\PYZsh{} depthwise convolution 에서는 }
                                  \PY{n}{stride} \PY{o}{=} \PY{n}{stride}\PY{p}{,}            \PY{c+c1}{\PYZsh{} in channel과 out channel의 수가 같다 }
                                  \PY{n}{kernel\PYZus{}size} \PY{o}{=} \PY{n}{kernel\PYZus{}size}\PY{p}{,}
                                  \PY{n}{padding} \PY{o}{=} \PY{n}{padding}\PY{p}{,} 
                                  \PY{n}{dilation} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,} 
                                  \PY{n}{bias} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} 
                                  \PY{n}{groups} \PY{o}{=} \PY{n}{in\PYZus{}channels} \PY{c+c1}{\PYZsh{}가장 중요한 부분! channel별로 할꺼니까 inchannel 의 개수와 같게! }
                                  \PY{p}{)}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{pointwise} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{n}{in\PYZus{}channels}\PY{o}{=}\PY{n}{in\PYZus{}channels}\PY{p}{,} 
                                      \PY{n}{out\PYZus{}channels} \PY{o}{=} \PY{n}{out\PYZus{}channels}\PY{p}{,} 
                                      \PY{n}{kernel\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{stride} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{dilation}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{groups} \PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{bias}\PY{o}{=}\PY{n}{bias}\PY{p}{)}
            
          \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
            \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1}\PY{p}{(}\PY{n}{x}\PY{p}{)}
            \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{pointwise}\PY{p}{(}\PY{n}{x}\PY{p}{)}
            \PY{k}{return} \PY{n}{x} 
\end{Verbatim}


    위 class 를 기반으로 모델에서 계속 사용이 되는 Block 을 만들게됩니다.

사진에서 보라색 박스를 만드는 것!

\textbf{Parameters} - reps: separable convolution 이 그 블록 안에 몇번
있느냐? (Middle Flow 에서는 3번, 그 외에는 2번) - start\_with\_relu:
convolution 앞에 ReLU 가 있느냐? (첫 블록만 false 고 다 ReLU 로
시작한다) - grow\_first: 필터의 개수가 그 블럭의 첫 convolution 을 할 때
증가하느냐 마지막 convolution 을 할 때 증가하느냐 (마지막 블록만 false
고 다 true)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k}{class} \PY{n+nc}{Block}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{in\PYZus{}filters}\PY{p}{,} \PY{n}{out\PYZus{}filters}\PY{p}{,} \PY{n}{reps}\PY{p}{,} 
                          \PY{n}{strides}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb}{super}\PY{p}{(}\PY{n}{Block}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
         
               \PY{c+c1}{\PYZsh{} skip 은 Residual을 가르킨다}
               \PY{c+c1}{\PYZsh{} 인풋과 아웃풋의 필터의 개수가 다르다면 개수를 맞춰주기 위해}
               \PY{c+c1}{\PYZsh{} 필터의 개수가 맞게 convolution 을 진행해야함 \PYZhy{}\PYZgt{} kernel의 크기는 1로 }
                 \PY{k}{if} \PY{n}{out\PYZus{}filters} \PY{o}{!=} \PY{n}{in\PYZus{}filters} \PY{o+ow}{or} \PY{n}{strides}\PY{o}{!=}\PY{l+m+mi}{1}\PY{p}{:}
                     \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{skip} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{n}{in\PYZus{}filters}\PY{p}{,}\PY{n}{out\PYZus{}filters}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{stride}\PY{o}{=}\PY{n}{strides}\PY{p}{,} \PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
                     \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{skipbn} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{n}{out\PYZus{}filters}\PY{p}{)}
                 \PY{k}{else}\PY{p}{:}       
                     \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{skip}\PY{o}{=}\PY{k+kc}{None}    \PY{c+c1}{\PYZsh{}인풋과 아웃풋 필터의 개수가 같다면 조정할 필요 없음}
                 
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n}{rep}\PY{o}{=}\PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{}모든 computation 을 rep 에 저장하기}
         
                 \PY{n}{filters} \PY{o}{=} \PY{n}{in\PYZus{}filters}
                 \PY{k}{if} \PY{n}{grow\PYZus{}first}\PY{p}{:} \PY{c+c1}{\PYZsh{}필터의 개수를 늘리고 시작하는 블록이라면}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{)}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{SeparableConv2d}\PY{p}{(}\PY{n}{in\PYZus{}filters}\PY{p}{,}\PY{n}{out\PYZus{}filters}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{)}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{n}{out\PYZus{}filters}\PY{p}{)}\PY{p}{)}
                     \PY{n}{filters} \PY{o}{=} \PY{n}{out\PYZus{}filters}
         
                 \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{reps}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:} \PY{c+c1}{\PYZsh{} 블록에 Depthwise convolution이 몇번 있느냐?}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{)}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{SeparableConv2d}\PY{p}{(}\PY{n}{filters}\PY{p}{,}\PY{n}{filters}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{)}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{n}{filters}\PY{p}{)}\PY{p}{)}
                 
                 \PY{k}{if} \PY{o+ow}{not} \PY{n}{grow\PYZus{}first}\PY{p}{:} \PY{c+c1}{\PYZsh{} 필터의 개수를 마지막에 늘리는 블록이라면 }
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{)}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{SeparableConv2d}\PY{p}{(}\PY{n}{in\PYZus{}filters}\PY{p}{,}\PY{n}{out\PYZus{}filters}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{n}{stride}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{)}
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{n}{out\PYZus{}filters}\PY{p}{)}\PY{p}{)}
         
                 \PY{k}{if} \PY{o+ow}{not} \PY{n}{start\PYZus{}with\PYZus{}relu}\PY{p}{:} \PY{c+c1}{\PYZsh{}ReLU 로 시작하지 않으면 앞에 ReLU 하나 떼어내가 }
                     \PY{n}{rep} \PY{o}{=} \PY{n}{rep}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}
                 \PY{k}{else}\PY{p}{:}
                     \PY{n}{rep}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
         
                 \PY{k}{if} \PY{n}{strides} \PY{o}{!=} \PY{l+m+mi}{1}\PY{p}{:} \PY{c+c1}{\PYZsh{} stride 가 1이 아니면 MaxPooling을 적용한다 }
                     \PY{n}{rep}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{MaxPool2d}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,}\PY{n}{strides}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{rep} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}\PY{o}{*}\PY{n}{rep}\PY{p}{)}
         
             \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,}\PY{n}{inp}\PY{p}{)}\PY{p}{:}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{rep}\PY{p}{(}\PY{n}{inp}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{}Residual Network의 필터개수 맞춰주기}
                 \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{skip} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
                     \PY{n}{skip} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{skip}\PY{p}{(}\PY{n}{inp}\PY{p}{)}
                     \PY{n}{skip} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{skipbn}\PY{p}{(}\PY{n}{skip}\PY{p}{)}
                 \PY{k}{else}\PY{p}{:}
                     \PY{n}{skip} \PY{o}{=} \PY{n}{inp}
                 
                 \PY{c+c1}{\PYZsh{}Residual 연결}
                 \PY{n}{x}\PY{o}{+}\PY{o}{=}\PY{n}{skip}
                 \PY{k}{return} \PY{n}{x}
\end{Verbatim}


    이제 드디어 Xception class 를 만들 준비가 끝났습니다!

헷갈리지 않게 각 블록마다 이름을 만들어서 function 을 만들어줍니다

여기서 num\_classes 는 분류하려는 카테고리의 개수입니다.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k}{class} \PY{n+nc}{Xception}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:} 
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb}{super}\PY{p}{(}\PY{n}{Xception}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
         
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{num\PYZus{}classes} \PY{o}{=} \PY{n}{num\PYZus{}classes}
                 
                 \PY{c+c1}{\PYZsh{}Entry Flow 에서 쓸 함수 정의하기}
                 \PY{c+c1}{\PYZsh{}모든 convolution 다음에는 batch norm이 온다 }
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn1} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{ReLU}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{n}{bias}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn2} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}ReLU 넣는거 까먹지 않기!}
         
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block1}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block2}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{256}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block3}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{256}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}Entry Flow 의 아웃풋은 19x 19 x 728 feature maps}
                 
                 \PY{c+c1}{\PYZsh{} Middle Flow 에서 쓸 함수: 같은거 8번 반복}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block4}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block5}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block6}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block7}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block8}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block9}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block10}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block11}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}Middle Flow 의 아웃풋은 19 x 19 x 728 feature maps\PYZhy{}\PYZgt{} 크기는 같음}
         
                 \PY{c+c1}{\PYZsh{}Exit Flow 에서 쓸 함수}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block12}\PY{o}{=}\PY{n}{Block}\PY{p}{(}\PY{l+m+mi}{728}\PY{p}{,}\PY{l+m+mi}{1024}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{start\PYZus{}with\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{grow\PYZus{}first}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3} \PY{o}{=} \PY{n}{SeparableConv2d}\PY{p}{(}\PY{l+m+mi}{1024}\PY{p}{,}\PY{l+m+mi}{1536}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn3} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{l+m+mi}{1536}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}ReLU 넣는거 까먹지 않기!}
         
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4} \PY{o}{=} \PY{n}{SeparableConv2d}\PY{p}{(}\PY{l+m+mi}{1536}\PY{p}{,}\PY{l+m+mi}{2048}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn4} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{(}\PY{l+m+mi}{2048}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}ReLU 넣는거 까먹지 않기!}
         
                 \PY{c+c1}{\PYZsh{}Optional FC Layer }
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{l+m+mi}{2048}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{} init weights \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
                 \PY{k}{for} \PY{n}{m} \PY{o+ow}{in} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{modules}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                     \PY{k}{if} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{m}\PY{p}{,} \PY{n}{nn}\PY{o}{.}\PY{n}{Conv2d}\PY{p}{)}\PY{p}{:}
                         \PY{n}{n} \PY{o}{=} \PY{n}{m}\PY{o}{.}\PY{n}{kernel\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{m}\PY{o}{.}\PY{n}{kernel\PYZus{}size}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{*} \PY{n}{m}\PY{o}{.}\PY{n}{out\PYZus{}channels}
                         \PY{n}{m}\PY{o}{.}\PY{n}{weight}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{normal\PYZus{}}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{math}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mf}{2.} \PY{o}{/} \PY{n}{n}\PY{p}{)}\PY{p}{)}
                     \PY{k}{elif} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{m}\PY{p}{,} \PY{n}{nn}\PY{o}{.}\PY{n}{BatchNorm2d}\PY{p}{)}\PY{p}{:}
                         \PY{n}{m}\PY{o}{.}\PY{n}{weight}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{fill\PYZus{}}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
                         \PY{n}{m}\PY{o}{.}\PY{n}{bias}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{zero\PYZus{}}\PY{p}{(}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         
             \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{:}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv1}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn1}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv2}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn2}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block1}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block2}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block3}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block4}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block5}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block6}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block7}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block8}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block9}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block10}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block11}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{block12}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv3}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn3}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{conv4}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{bn4}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{x}\PY{p}{)}
         
                 \PY{n}{x} \PY{o}{=} \PY{n}{F}\PY{o}{.}\PY{n}{adaptive\PYZus{}avg\PYZus{}pool2d}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{view}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc}\PY{p}{(}\PY{n}{x}\PY{p}{)}
         
                 \PY{k}{return} \PY{n}{x}
\end{Verbatim}


    논문에서 얘기한 대로 구조가 계속 반복되고 간단해서 쉽게 만들 수
있습니다. 여기서 Pretrained weight 를 쓰고싶다면 weight 를 불러오는
function 만 만들어주면 됩니다.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k}{def} \PY{n+nf}{xception}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}\PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
         
             \PY{n}{model} \PY{o}{=} \PY{n}{Xception}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}
             \PY{k}{if} \PY{n}{pretrained}\PY{p}{:}
                 \PY{n}{model}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{model\PYZus{}zoo}\PY{o}{.}\PY{n}{load\PYZus{}url}\PY{p}{(}\PY{n}{model\PYZus{}urls}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{xception}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{n}{model}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
