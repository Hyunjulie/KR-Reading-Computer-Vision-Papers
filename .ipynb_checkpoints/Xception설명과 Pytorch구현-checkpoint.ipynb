{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이제는 기본 모델이 된 'Xception' 이해하기! \n",
    "\n",
    "Pretrained 된 모델을 사용하거나 Transfer Learning 을 사용하는 모델들에 대해서 읽을 때 Backbone (척추같은 존재 ^0^)가 되는 CNN 모델들이 몇 개 있습니다. \n",
    "VGG family, ResNet family, Inception family, 그리고 Xception. \n",
    "더 복잡한 작업(e.g. Semantic Segmentation 등)의 기초가 되는 이 네트워크, 특히 Xception, 에 대해서 제대로 알아야겠다는 생각이 들어서 정리해보았습니다. \n",
    "\n",
    "\n",
    "\n",
    "### 목차 \n",
    "1. Xception 의 바탕이 되는 'Inception Family' 정리\n",
    "2. Xception 의 핵심 포인트, Modified Depthwise Separable Convolution 이해하기\n",
    "3. Overall Architecture\n",
    "4. Pytorch 로 구현해보는 Xception \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Xception 모델이란? \n",
    "\n",
    "Xception 은 구글이 2017년에 발표한 모델로, 2015년에 ILSVRC 대회에서 2등을 한 Google 의 Inception-V3 모델보다 훨씬 좋은 결과를 냈습니다. \n",
    "- Encoder-Decoder 형태의 모델들에서 pretrain 된 Xception 모델이 Encoder로 자주 쓰입니다. 또한 Xception 에서 제시하는 모델의 구조나 핵심인 'modified depthwise separable convolution'의 개념이 간단하기 때문에 다른 모델에도 적용하기 쉽습니다. \n",
    "- Xception 이라는 이름 자체가 Extreme + Inception 에서 나온 만큼 Inception 모델이 기본이 된다는 것을 알 수 있으니까, 먼저 Inception 모델들에 대해서 간단하게 정리하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inception Family 의 포인트 정리 \n",
    "\n",
    "Inception 모델은 지금까지 version 4과 ResNet이 합쳐진 Inception-ResNet v2 까지 나왔습니다. 각 모델에 대한 설명은 https://norman3.github.io/papers/docs/google_inception.html 여기를 참고하면 자세한 정보를 얻으실 수 있습니다. \n",
    "\n",
    "\n",
    "맛보기로 Inception-ResNet V2의 Architecture 입니다: \n",
    "  <img src=\"images/inceptionresnetv4.png\" width=\"800\" height=\"800\" />\n",
    "\n",
    "다른 모델에 활용하기에는 복잡해서 연산량이나 parameter의 개수가 VGG보다 훨씬 적음에도 불구하고 vgg net이 더 자주 사용된다고하네요 :( \n",
    "\n",
    "\n",
    "\n",
    "** - Inception 모델의 목적? **\n",
    "\n",
    "\n",
    "딥러닝은 망이 깊을수록 (deep), 레이어가 넓을수록 (wide) 성능이 좋지만, overfitting & vanishing gradient 의 문제로 깊고 넓게만 모델을 만드는 것은 문제가 됩니다. \n",
    "Inception 은 Convolution 레이어를 sparse 하게 연결하면서 행렬 연산은 dense하게 처리하기 위해 고안한 모델입니다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "** - 다른 Convolution과 어떻게 다른가? **\n",
    "\n",
    "보통 5x5 또는 7x7의 하나의 convolution 필터로 진행하는데, Inception 모델에서는 conv 레이어 여러 개를 한 층에서 구성하는 형태를 취하고 있습니다.  \n",
    "영화 Inception 에서 이름을 따온 이유가 여기 있습니다! '동시에' (같은 Layer에서) 다양한 convolution 을 진행하기 때문이죠 \n",
    "\n",
    "  <img src=\"images/naive.png\" width=\"500\" height=\"300\" />\n",
    "\n",
    " - 왜 굳이 귀찮게 하는가? Parameter 의 개수도 줄이고, 연산량도 줄일 수 있기 때문!\n",
    " - Kernel size가 늘어날수록 연산량의 크기가 굉장히 커지기 때문에 나중에는 5x5 가 아니라 3x3을 2번 하는 방향으로 바뀝니다 -> 더 나아가서 3x3 를 쪼개서 3x1 과 1x3 convolution 을 2번하는 방향으로 가기도 합니다 (Asymmetric Convolution Factorizing 이라고 부릅니다)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "** - 1x1 Convolution 을 하는 이유? **\n",
    "\n",
    "\n",
    "Convolution의 연산은 [Batch Size, Width, Height, Channel], 4차원의 데이터로 표기합니다. 보통의 convolution 은 채널의 개수를 늘리지만,1x1 연산의 목적은 채널의 개수를 줄여서 압축하는데에 있습니다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "** - Residual Network 를 사용하면 좋은 점? **\n",
    "<img src=\"images/limit.png\" width=\"400\" height=\"240\" />\n",
    "\n",
    "위 그래프와 같이 학습 수렴 속도가 빨라집니다. \n",
    "\n",
    "\n",
    "- 잠깐 복습! Residual Net 이란? \n",
    "<table><tr>\n",
    "<td> <img src=\"images/res1.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"images/res2.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "왼쪽: 가장 간단한 형태의 residual-connection | 오른쪽: 1 x 1 conv 를 추가해서 연산량을 줄인 모델\n",
    "\n",
    "ResNet 은 간단하게 얘기하면: 몇 단계 전 레이어의 결과를 현재 레이어의 결과와 합쳐 내보내는 네트워크입니다.\n",
    "\n",
    "\n",
    "---\n",
    "        즉, 정리하자면 'Inception' 모델들의 내용은: \n",
    "\n",
    "A. Convolution 을 할 때 하나의 큰 kernel 을 사용할게 아니라 다양한 크기를 이어붙이는것이 연산량 & parameter의 개수도 적도, 좋은 결과를 얻을 수 있다! \n",
    "\n",
    "\n",
    "B. 거기에 ResNet 넣으면 수렴속도도 빨라지고 \n",
    "\n",
    "\n",
    "C. 하는김에 Factorization 까지 하면 더 연산량도 줄고 \n",
    "\n",
    "\n",
    "--> 어떻게 Inception module 을 구성하느냐에 따라 버젼이 바뀝니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## 오늘의 주제, Xception 모델! \n",
    "\n",
    "- Xception의 중점 포인트: **Modified Depthwise Separable Convolution**\n",
    "    - 오리지널 Depthwise Separable Convolution 이란?\n",
    "    - Modified? 뭐가 바뀌었나? \n",
    "\n",
    "\n",
    "- Xception 의 목적? 연산량과 parameter의 개수를 줄여서, 큰 이미지 인식을 고속화 시키자! \n",
    "\n",
    "장점: VGG처럼 네트워크의 구조가 간단해서 (inception 과 달리..) 활용도가 높다! \n",
    "\n",
    "\n",
    "- 논문에서 얘기하는 Xception 의 바탕이 된 개념들\n",
    "1. VGG16의 구조: Deep 하게 쌓아가는 구조를 따온 점!\n",
    "2. Inception Family: Conv 를 할 때 몇개의 branch 로 factorize 해서 진행하는 것의 장점을 알려준 점!\n",
    "3. Depthwise Separable Convolution: 가장 중요한 개념! 네트워크의 사이즈와 연산량을 줄이기 위한 연구 (채널별로 conv 를 진행한 후 space 에 대해서 conv 를 진행한다) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modified Depthwise Separable Convolution\n",
    "\n",
    "#### 1) 일단, 원조 'Depthwise Separable Convolution'은 무엇인가? \n",
    "Depthwise(깊이 별로 == 채널 별로) Separable(나누어서) convolution 을 하는 것!\n",
    "일반 Convolution과 결과는 같지만 두 단계로 진행됩니다. \n",
    "\n",
    "<img src=\"images/original depthwise convolution.png\" width=\"600\" height=\"350\" />\n",
    "\n",
    "** 1단계: Channel-wise nxn spatial convolution **\n",
    "\n",
    "위에 그림에서와 같이 인풋으로 5개의 채널이 들어오면 5개의 n x n convolution 을 따로 진행해서 합칩니다. \n",
    "\n",
    "** 2단계: Pointwise Convolution ** \n",
    "\n",
    "원래 우리가 알고있는 1x1 convolution입니다. 채널의 개수를 줄이기 위한 방법으로 사용됩니다. \n",
    "\n",
    "\n",
    "\n",
    "예시: 밑에와 같이 256 x 256 x 3 의 인풋이 있을 때 \n",
    "\n",
    "<img src=\"images/original.png\" width=\"400\" height=\"250\" />\n",
    "\n",
    "1단계에서는: 256 x 256 x 1 을 3번 진행해서 concat을 합니다\n",
    "\n",
    "2단계에서는: pointwise convolution을 이용해서 채널의 개수를 1개로 줄입니다! (단순하게 weighted sum 을 계산하는 것) \n",
    "\n",
    "- 결과적으로는 같은데, 왜 굳이 2단계로 나눠서 하는가? \n",
    "위와같은 과정으로 Convolution 을 하면 약 9배 정도 빠르다고 합니다. \n",
    "\n",
    "일반 convolution 의 계산량 \n",
    "- 특징 맵의 크기: F x F \n",
    "- 입력 채널 수: N \n",
    "- 커널 크기: K x K \n",
    "- 출력 채널 수: M \n",
    "- 계산량 F x F x N x K x K x M\n",
    "- Parameter 수: K x K x N x M \n",
    "\n",
    "Point-wise 의 계산량 \n",
    "- 같은 크기의 아웃풋을 만들어 낸다 \n",
    "- 특징 맵의 차원을 늘리거나 줄일 때 사용된다 \n",
    "- K = 1 으로 만든 것. \n",
    "- 계산량은 F x F x N x M \n",
    "- Parameter 수: N x M \n",
    "Depthwise: 특징맵 채널마다 각각 공간 방향의 convolution 을 한다 \n",
    "- 채널방향으로 수행하지 않기 때문에 일반 convolution 1회의 cost -> K x K \n",
    "- 계산량: F x F x N x K x K \n",
    "- Parameter: K x K x N \n",
    "\n",
    "\n",
    "결론: 계산량: FxFxNxKxKxM --> FxFxNxM + FxFxNxKxK로 감소 \n",
    "\n",
    "\n",
    "즉, 1/K^2 + 1/M 으로 됩니다--> 보통 M >> K^2 이므로 계산량은 1/9정도가 됩니다\n",
    "\n",
    "\n",
    "\n",
    "##### 2) Xception 의 'Modified' 는 뭐가 달라졌는가? \n",
    "- 연산의 순서: 원래는 depthwise 를 진행하고, pointwise 를 했는데, 이제는 pointwise -> depthwise 로 바꿈\n",
    "\n",
    "- Non-Linearity 의 유무: Inception 모델의 경우, 첫 연산 후에 non-linearity (ReLU)가 있지만, Xception은 중간에 ReLU non-linearity 를 적용하지 않는다\n",
    "\n",
    "- Residual connection 이 거의 모든 Layer 에 있다 -> 없애고 실험해봤더니 있을때의 정확도가 훨씬 높았음. residual connection 이 굉장히 중요한 요소임\n",
    "\n",
    "구조 자체는 굉장히 간단해서 밑에 있는 사진을 보면 쉽게 이해가 갑니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Architecture \n",
    "\n",
    "Entry, Middle, Exit의 3개 구조로 나뉩니다. \n",
    "\n",
    "1.   Entry Flow\n",
    "  - 인풋: 229 x 229 x 3 \n",
    "  - 모든 convolutional layer 다음에는 batch normalization 을 사용한다 \n",
    "  - 2번 normal convolution (3x3) -> 필터의 갯수: 32 -> 64\n",
    "  - Residual Network 가 합쳐진 Inception Module 3번 \n",
    "\n",
    "2.   Middle Flow\n",
    "  - 반복되는 단순한 모델: 필터의 개수와 width/height 는 바뀌지 않는다 \n",
    "  - ReLU -> Separable Conv -> Separable Conv 이걸 8번 반복하기 \n",
    " \n",
    "3.   Exit Flow\n",
    "  - filter의 개수를 늘린다음 -> Maxpooling -> 2번 separable convolution -> Global Average Pooling -> Optional Fully-Connected -> Logistic Regression \n",
    "  \n",
    "  <img src=\"images/xception architecture.png\" width=\"800\" height=\"400\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 로 구현해보기! \n",
    "\n",
    "위 코드는 https://github.com/tstandley/Xception-PyTorch 위 깃헙에서 대부분을 가져왔습니다! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f \n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import init \n",
    "\n",
    "# Pretrained 된 weight 를 사용할 때 필요합니다. weight 들이 담긴 파일을 다운받는 링크입니다\n",
    "model_urls = {'xception':'https://www.dropbox.com/s/1hplpzet9d7dv29/xception-c0a72b38.pth.tar?dl=1'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에서 기본으로 사용되는 \n",
    "'Convolution' -> 'Pointwise Convolution' 을 하나의 class 로 묶어서 재사용할 수 있게 합니다.\n",
    "\n",
    "사진에 있는 빨간 동그라미 하나를 만드는 것!\n",
    "  <img src=\"images/xception architecture2.png\" width=\"400\" height=\"200\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding =0, dilation=1, bias=False):\n",
    "    #nn.Module 을 상속받게 만들기 \n",
    "    super(SeparableConv2d, self).__init__()\n",
    "    \n",
    "    #Forward 에서 쓸 함수들을 정의해주기\n",
    "    self.conv1 = nn.Conv2d(in_channels = in_channels, \n",
    "                          out_channels = in_channels, # depthwise convolution 에서는 \n",
    "                          stride = stride,            # in channel과 out channel의 수가 같다 \n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = padding, \n",
    "                          dilation = 1, \n",
    "                          bias = False, \n",
    "                          groups = in_channels #가장 중요한 부분! channel별로 할꺼니까 inchannel 의 개수와 같게! \n",
    "                          )\n",
    "    self.pointwise = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels = out_channels, \n",
    "                              kernel_size = 1, stride = 1, padding=0, dilation=1, groups =1, bias=bias)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.pointwise(x)\n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 class 를 기반으로 모델에서 계속 사용이 되는 Block 을 만들게됩니다. \n",
    "  <img src=\"images/xception architecture3.png\" width=\"400\" height=\"200\" />\n",
    "\n",
    "사진에서 보라색 박스를 만드는 것!\n",
    "\n",
    "**Parameters**\n",
    "- reps: separable convolution 이 그 블록 안에 몇번 있느냐? (Middle Flow 에서는 3번, 그 외에는 2번) \n",
    "- start_with_relu: convolution 앞에 ReLU 가 있느냐? (첫 블록만 false 고 다 ReLU 로 시작한다)\n",
    "- grow_first: 필터의 개수가 그 블럭의 첫 convolution 을 할 때 증가하느냐 마지막 convolution 을 할 때 증가하느냐 (마지막 블록만 false 고 다 true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, reps, \n",
    "                 strides=1, start_with_relu=True, grow_first=True):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "      # skip 은 Residual을 가르킨다\n",
    "      # 인풋과 아웃풋의 필터의 개수가 다르다면 개수를 맞춰주기 위해\n",
    "      # 필터의 개수가 맞게 convolution 을 진행해야함 -> kernel의 크기는 1로 \n",
    "        if out_filters != in_filters or strides!=1:\n",
    "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
    "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
    "        else:       \n",
    "            self.skip=None    #인풋과 아웃풋 필터의 개수가 같다면 조정할 필요 없음\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep=[] #모든 computation 을 rep 에 저장하기\n",
    "\n",
    "        filters = in_filters\n",
    "        if grow_first: #필터의 개수를 늘리고 시작하는 블록이라면\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "            filters = out_filters\n",
    "\n",
    "        for i in range(reps-1): # 블록에 Depthwise convolution이 몇번 있느냐?\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "        \n",
    "        if not grow_first: # 필터의 개수를 마지막에 늘리는 블록이라면 \n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "\n",
    "        if not start_with_relu: #ReLU 로 시작하지 않으면 앞에 ReLU 하나 떼어내가 \n",
    "            rep = rep[1:]\n",
    "        else:\n",
    "            rep[0] = nn.ReLU(inplace=False)\n",
    "\n",
    "        if strides != 1: # stride 가 1이 아니면 MaxPooling을 적용한다 \n",
    "            rep.append(nn.MaxPool2d(3,strides,1))\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self,inp):\n",
    "        x = self.rep(inp)\n",
    "        \n",
    "        #Residual Network의 필터개수 맞춰주기\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "        \n",
    "        #Residual 연결\n",
    "        x+=skip\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 드디어 Xception class 를 만들 준비가 끝났습니다! \n",
    "\n",
    "헷갈리지 않게 각 블록마다 이름을 만들어서 function 을 만들어줍니다 \n",
    "\n",
    "여기서 num_classes 는 분류하려는 카테고리의 개수입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module): \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #Entry Flow 에서 쓸 함수 정의하기\n",
    "        #모든 convolution 다음에는 batch norm이 온다 \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        #ReLU 넣는거 까먹지 않기!\n",
    "\n",
    "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
    "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
    "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
    "        #Entry Flow 의 아웃풋은 19x 19 x 728 feature maps\n",
    "        \n",
    "        # Middle Flow 에서 쓸 함수: 같은거 8번 반복\n",
    "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        #Middle Flow 의 아웃풋은 19 x 19 x 728 feature maps-> 크기는 같음\n",
    "\n",
    "        #Exit Flow 에서 쓸 함수\n",
    "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
    "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "        #ReLU 넣는거 까먹지 않기!\n",
    "\n",
    "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
    "        self.bn4 = nn.BatchNorm2d(2048)\n",
    "        #ReLU 넣는거 까먹지 않기!\n",
    "\n",
    "        #Optional FC Layer \n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        #------- init weights --------\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        #-----------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에서 얘기한 대로 구조가 계속 반복되고 간단해서 쉽게 만들 수 있습니다. \n",
    "여기서 Pretrained weight 를 쓰고싶다면 weight 를 불러오는 function 만 만들어주면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception(pretrained=False,**kwargs):\n",
    "\n",
    "    model = Xception(**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['xception']))\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
