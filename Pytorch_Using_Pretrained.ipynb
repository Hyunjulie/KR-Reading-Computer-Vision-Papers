{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Using_Pretrained.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Hyunjulie/KR-Reading-Image-Segmentation-Papers/blob/master/Pytorch_Using_Pretrained.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nxuCpFZO1CxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "ef751ba7-90a2-484a-8642-3375107e2f6e"
      },
      "cell_type": "code",
      "source": [
        "#Load Pytorch \n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 592.3MB 117.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X793KWQa1Lmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler \n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time \n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sZkrhGA1QOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Examples of models supproted by torchvision.modles\n",
        "vgg16 = models.vgg16_bn()\n",
        "resnet50 = models.resnet50()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWm27Gyj1gr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "21bf4dcf-fd23-4fc8-833b-bef60c86033a"
      },
      "cell_type": "code",
      "source": [
        "#Exploration on ResNet50 Model\n",
        "#Pretrained 된 model 을 그냥 가져다가 쓸 때 --> 이번에는 ResNet 을 사용해서 \n",
        "# 마지막 FC layer의 output class를 나의 데이터에 맞춰서 바꿔야 한다 \n",
        "#일단 ResNet이 어떻게 생겼는지 Explore 할 수 있음 \n",
        "\n",
        "#간단하게는 parameter만 print 할 수 있고 \n",
        "for name, params in resnet50.named_children():\n",
        "  print(name)\n",
        "  \n",
        "# #모든 layer의 function들까지 다 보고 싶으면 \n",
        "# for name, child in resnet50.named_children():\n",
        "#   for name2, params in child.named_parameters():\n",
        "#     print(name, name2)\n",
        "    \n",
        "#마지막 layer가 fc 인걸 아니까 \n",
        "print(resnet50.fc)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1\n",
            "bn1\n",
            "relu\n",
            "maxpool\n",
            "layer1\n",
            "layer2\n",
            "layer3\n",
            "layer4\n",
            "avgpool\n",
            "fc\n",
            "Linear(in_features=2048, out_features=1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sbtmUUYG2gea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08957044-d1fd-45b9-f52b-5f1df12591d8"
      },
      "cell_type": "code",
      "source": [
        "#아니면 간단하게 \n",
        "num_ftrs = resnet50.fc.in_features\n",
        "out_ftrs = resnet50.fc.out_features\n",
        "resnet50.fc = nn.Linear(num_ftrs,10) \n",
        "#필요한 output class의 개수만큼 fc 의 output filter 를 바꿔준다 \n",
        "print(resnet50.fc) #바뀌어있음"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=2048, out_features=10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E0VWuhG23W1-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 원하는Layer 를 Freeze 해서 쓰기"
      ]
    },
    {
      "metadata": {
        "id": "gRsnpq5C3cXv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#params.requires_grad가 false 라면 back propagation 할 때 weight 가 learn이 안된다 \n",
        "\n",
        "#모든 layer 를 freeze 하기\n",
        "for params in resnet50.parameters():\n",
        "  params.requires_grad = False\n",
        "\n",
        "#앞에 몇개 Layer만 freeze하기 - 여기서는 첫 3개 layer만  \n",
        "ct = 0 \n",
        "for name, child in resnet50.named_children():\n",
        "  ct += 1 \n",
        "  if ct < 7: \n",
        "    for name2, params in child.named_parameters():\n",
        "      params.requires_grad = False \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "quE1Bhlg33Kf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 다른 예시 - SqueezeNet\n",
        "- Final layer 가 sequential 컨테이너 안에 있음 \n",
        "- 안에 있는 모든 child layer를 보고 나서 out 개수 재지정 하고 다시 컨테이너 안에 넣어야 한다 \n"
      ]
    },
    {
      "metadata": {
        "id": "_T_2Vxo_39_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        },
        "outputId": "578f96eb-e5ed-4b62-c33d-f6a6fb14dc25"
      },
      "cell_type": "code",
      "source": [
        "squeeze = torchvision.models.squeezenet1_1()\n",
        "for name, params in squeeze.named_children():\n",
        "  print(name)\n",
        "  \n",
        "#Feature 과 Classifier에 각각 어떤 child layer 가 있는지 혹시 보고 싶으면\n",
        "print(list(squeeze.features.children()))\n",
        "print(list(squeeze.classifier.children()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features\n",
            "classifier\n",
            "[Conv2d (3, 64, kernel_size=(3, 3), stride=(2, 2)), ReLU(inplace), MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1)), Fire(\n",
            "  (squeeze): Conv2d (64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), Fire(\n",
            "  (squeeze): Conv2d (128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1)), Fire(\n",
            "  (squeeze): Conv2d (128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), Fire(\n",
            "  (squeeze): Conv2d (256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1)), Fire(\n",
            "  (squeeze): Conv2d (256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), Fire(\n",
            "  (squeeze): Conv2d (384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), Fire(\n",
            "  (squeeze): Conv2d (384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            "), Fire(\n",
            "  (squeeze): Conv2d (512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (squeeze_activation): ReLU(inplace)\n",
            "  (expand1x1): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (expand1x1_activation): ReLU(inplace)\n",
            "  (expand3x3): Conv2d (64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (expand3x3_activation): ReLU(inplace)\n",
            ")]\n",
            "[Dropout(p=0.5), Conv2d (512, 1000, kernel_size=(1, 1), stride=(1, 1)), ReLU(inplace), AvgPool2d(kernel_size=13, stride=1, padding=0, ceil_mode=False, count_include_pad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xlaGhcIr4Eoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12dcf47c-4bbf-491e-96d3-7a7e0a446081"
      },
      "cell_type": "code",
      "source": [
        "#how many in_channels are there for conv layer \n",
        "in_ftrs = squeeze.classifier[1].in_channels\n",
        "print(in_ftrs)\n",
        "#위에 셀에 있는 마지막 convolution layer 의 shape을 보면 사실 알 수 있음 \n",
        "\n",
        "out_ftrs = squeeze.classifier[1].out_channels\n",
        "print(out_ftrs)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8DNdaxit4F9p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "마지막 convolutional layer 의 output 사이즈를 바꾸기 \n",
        "\n",
        "\n",
        "squeeze net 은  마지막 layer 가 그냥 fc layer 로 되어 있는게 아니라 \n",
        "- Classifier라고 불리는 컨테이너 안에 마지막 layer가 포함되어 있기 때문에 \n",
        "- 컨테이너를 리스트로 풀고 \n",
        "- 마지막 layer를 바꾸고 \n",
        "- 다시 리스트를 컨테이너에 넣어서 \n",
        "- 연결해야한다 "
      ]
    },
    {
      "metadata": {
        "id": "R-5Uo01i4sPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1a17867c-62ae-4462-87cc-ed07422816b2"
      },
      "cell_type": "code",
      "source": [
        "#classfier 의 layer를 리스트로 변환하기 \n",
        "features = list(squeeze.classifier.children())\n",
        "print(features)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Dropout(p=0.5), Conv2d (512, 1000, kernel_size=(1, 1), stride=(1, 1)), ReLU(inplace), AvgPool2d(kernel_size=13, stride=1, padding=0, ceil_mode=False, count_include_pad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "413JEaPJ4uHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 마지막 conv layer 를 내가 원하는 사이즈로 바꾸기 --> output class 의 갯수로 \n",
        "features[1] = nn.Conv2d(in_ftrs, 100, kernel_size=(1,1), stride=(1,1))\n",
        "features[3] = nn.AvgPool2d(12, stride=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GTu99NKQ4xJN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#다시 붙어넣기 \n",
        "squeeze.classifier = nn.Sequential(*features)\n",
        "\n",
        "#바뀌어 있는걸 확인하기\n",
        "print(list(squeeze.classifier.children()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dFw3NOFO49QA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 또 다른 예시 - VGG Net \n",
        "- 얘 또한 fc layer 가 컨테이너 안에 들어있음. \n",
        "- 컨테이너가를 읽은 후에 마지막 fc layer 를 우리의 데이터셋에 맞춰서 바꾸면 된다 "
      ]
    },
    {
      "metadata": {
        "id": "uAZBz1Pu5FTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "849b4ff1-737a-4d2b-ff83-abcb58f2f22c"
      },
      "cell_type": "code",
      "source": [
        "vgg = torchvision.models.vgg19(pretrained='imagenet')\n",
        "\n",
        "print(list(vgg.classifier.children()))\n",
        "#마지막 linear layer (fc)가 in 은 4096개, out 은 1000개 인것을 알 수 있음"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.torch/models/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 574673361/574673361 [00:10<00:00, 55789494.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Linear(in_features=25088, out_features=4096), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=4096), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=1000)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2cQ-ks85JiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "140084de-e7c7-4958-dc36-aeaa3e4b91af"
      },
      "cell_type": "code",
      "source": [
        "#OR 다른 방법으로 마지막에 filter 개수 몇갠지 알아보는 방법 \n",
        "num_ftrs = vgg.classifier[-1].in_features\n",
        "#layer 가 몇개 있는지 모르면 걍 -1쓰기\n",
        "print(num_ftrs)\n",
        "\n",
        "#layer 를 list 로 바꾸고 마지막꺼만 없애기 \n",
        "features = list(vgg.classifier.children())[:-1]\n",
        "\n",
        "#맨 뒤에 원하는 class 의 개수에 따라서 n_class 를 조정해서 넣기 \n",
        "features.extend([nn.Linear(num_ftrs, 100)])\n",
        "\n",
        "##다시 붙여넣기 \n",
        "vgg.classifier = nn.Sequential(*features)\n",
        "print(list(vgg.classifier.children()))\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4096\n",
            "[Linear(in_features=25088, out_features=4096), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=4096), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=100)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BP-nFMEx5cf6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 또 다른 예시 ~ Inception V3\n"
      ]
    },
    {
      "metadata": {
        "id": "ZvyBgK3A5f73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "72e648c7-7edd-4735-c4de-3cd0bc74a194"
      },
      "cell_type": "code",
      "source": [
        "inception = torchvision.models.inception_v3(pretrained='imagenet')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.torch/models/inception_v3_google-1a9a5a14.pth\n",
            "100%|██████████| 108857766/108857766 [00:13<00:00, 7813116.32it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "M40Fonb25m77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4981
        },
        "outputId": "f8363b10-7e5e-42b6-b4ae-405c87edab31"
      },
      "cell_type": "code",
      "source": [
        "# 원하는 Layer만 freeze 해서 사용하는 방법~~~ \n",
        "# 일단 다 freeze 를 시킨다음에 원하는 layer  만 unfreeze 하는 2단계로 해야함\n",
        "\n",
        "#1) 모든 layer freeze 하기\n",
        "for i, param in inception.named_parameters():\n",
        "  param.requires_grad = False \n",
        "\n",
        "# imagenet 으로  pretrained 된거라서 마지막에 1000classes 로 분류가 된다. \n",
        "#마지막 layer 의 output 갯수를 원하는걸로 바꾸기 \n",
        "num_ftrs = inception.fc.in_features #일단 input을 몇개를 받고 있는지 확인하기 -> 똑같이 해줘야 함 \n",
        "inception.fc = nn.Linear(num_ftrs, 10) #원하는 output의 갯수로 바꿔주기 \n",
        "\n",
        "#print(list(inception.classifier.children()))\n",
        "#바뀐거 확인하고 싶으면\n",
        "\n",
        "\n",
        "#2) 특정 layer 전까지는 unfreeze 하기 \n",
        "ct = []\n",
        "for name, child in inception.named_children():\n",
        "  if \"Conv2d_4a_3x3\" in ct:\n",
        "    for params in child.parameters():\n",
        "      params.requires_grad = True\n",
        "  ct.append(name)\n",
        "#어떤 Layer가 freeze 됐는지 확인하기 \n",
        "for name, child in inception.named_children():\n",
        "  for name2, params in child.named_parameters():\n",
        "    print(name2, params.requires_grad)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv.weight False\n",
            "bn.weight False\n",
            "bn.bias False\n",
            "conv.weight False\n",
            "bn.weight False\n",
            "bn.bias False\n",
            "conv.weight False\n",
            "bn.weight False\n",
            "bn.bias False\n",
            "conv.weight False\n",
            "bn.weight False\n",
            "bn.bias False\n",
            "conv.weight False\n",
            "bn.weight False\n",
            "bn.bias False\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch5x5_1.conv.weight True\n",
            "branch5x5_1.bn.weight True\n",
            "branch5x5_1.bn.bias True\n",
            "branch5x5_2.conv.weight True\n",
            "branch5x5_2.bn.weight True\n",
            "branch5x5_2.bn.bias True\n",
            "branch3x3dbl_1.conv.weight True\n",
            "branch3x3dbl_1.bn.weight True\n",
            "branch3x3dbl_1.bn.bias True\n",
            "branch3x3dbl_2.conv.weight True\n",
            "branch3x3dbl_2.bn.weight True\n",
            "branch3x3dbl_2.bn.bias True\n",
            "branch3x3dbl_3.conv.weight True\n",
            "branch3x3dbl_3.bn.weight True\n",
            "branch3x3dbl_3.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch5x5_1.conv.weight True\n",
            "branch5x5_1.bn.weight True\n",
            "branch5x5_1.bn.bias True\n",
            "branch5x5_2.conv.weight True\n",
            "branch5x5_2.bn.weight True\n",
            "branch5x5_2.bn.bias True\n",
            "branch3x3dbl_1.conv.weight True\n",
            "branch3x3dbl_1.bn.weight True\n",
            "branch3x3dbl_1.bn.bias True\n",
            "branch3x3dbl_2.conv.weight True\n",
            "branch3x3dbl_2.bn.weight True\n",
            "branch3x3dbl_2.bn.bias True\n",
            "branch3x3dbl_3.conv.weight True\n",
            "branch3x3dbl_3.bn.weight True\n",
            "branch3x3dbl_3.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch5x5_1.conv.weight True\n",
            "branch5x5_1.bn.weight True\n",
            "branch5x5_1.bn.bias True\n",
            "branch5x5_2.conv.weight True\n",
            "branch5x5_2.bn.weight True\n",
            "branch5x5_2.bn.bias True\n",
            "branch3x3dbl_1.conv.weight True\n",
            "branch3x3dbl_1.bn.weight True\n",
            "branch3x3dbl_1.bn.bias True\n",
            "branch3x3dbl_2.conv.weight True\n",
            "branch3x3dbl_2.bn.weight True\n",
            "branch3x3dbl_2.bn.bias True\n",
            "branch3x3dbl_3.conv.weight True\n",
            "branch3x3dbl_3.bn.weight True\n",
            "branch3x3dbl_3.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch3x3.conv.weight True\n",
            "branch3x3.bn.weight True\n",
            "branch3x3.bn.bias True\n",
            "branch3x3dbl_1.conv.weight True\n",
            "branch3x3dbl_1.bn.weight True\n",
            "branch3x3dbl_1.bn.bias True\n",
            "branch3x3dbl_2.conv.weight True\n",
            "branch3x3dbl_2.bn.weight True\n",
            "branch3x3dbl_2.bn.bias True\n",
            "branch3x3dbl_3.conv.weight True\n",
            "branch3x3dbl_3.bn.weight True\n",
            "branch3x3dbl_3.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch7x7_1.conv.weight True\n",
            "branch7x7_1.bn.weight True\n",
            "branch7x7_1.bn.bias True\n",
            "branch7x7_2.conv.weight True\n",
            "branch7x7_2.bn.weight True\n",
            "branch7x7_2.bn.bias True\n",
            "branch7x7_3.conv.weight True\n",
            "branch7x7_3.bn.weight True\n",
            "branch7x7_3.bn.bias True\n",
            "branch7x7dbl_1.conv.weight True\n",
            "branch7x7dbl_1.bn.weight True\n",
            "branch7x7dbl_1.bn.bias True\n",
            "branch7x7dbl_2.conv.weight True\n",
            "branch7x7dbl_2.bn.weight True\n",
            "branch7x7dbl_2.bn.bias True\n",
            "branch7x7dbl_3.conv.weight True\n",
            "branch7x7dbl_3.bn.weight True\n",
            "branch7x7dbl_3.bn.bias True\n",
            "branch7x7dbl_4.conv.weight True\n",
            "branch7x7dbl_4.bn.weight True\n",
            "branch7x7dbl_4.bn.bias True\n",
            "branch7x7dbl_5.conv.weight True\n",
            "branch7x7dbl_5.bn.weight True\n",
            "branch7x7dbl_5.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch7x7_1.conv.weight True\n",
            "branch7x7_1.bn.weight True\n",
            "branch7x7_1.bn.bias True\n",
            "branch7x7_2.conv.weight True\n",
            "branch7x7_2.bn.weight True\n",
            "branch7x7_2.bn.bias True\n",
            "branch7x7_3.conv.weight True\n",
            "branch7x7_3.bn.weight True\n",
            "branch7x7_3.bn.bias True\n",
            "branch7x7dbl_1.conv.weight True\n",
            "branch7x7dbl_1.bn.weight True\n",
            "branch7x7dbl_1.bn.bias True\n",
            "branch7x7dbl_2.conv.weight True\n",
            "branch7x7dbl_2.bn.weight True\n",
            "branch7x7dbl_2.bn.bias True\n",
            "branch7x7dbl_3.conv.weight True\n",
            "branch7x7dbl_3.bn.weight True\n",
            "branch7x7dbl_3.bn.bias True\n",
            "branch7x7dbl_4.conv.weight True\n",
            "branch7x7dbl_4.bn.weight True\n",
            "branch7x7dbl_4.bn.bias True\n",
            "branch7x7dbl_5.conv.weight True\n",
            "branch7x7dbl_5.bn.weight True\n",
            "branch7x7dbl_5.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch7x7_1.conv.weight True\n",
            "branch7x7_1.bn.weight True\n",
            "branch7x7_1.bn.bias True\n",
            "branch7x7_2.conv.weight True\n",
            "branch7x7_2.bn.weight True\n",
            "branch7x7_2.bn.bias True\n",
            "branch7x7_3.conv.weight True\n",
            "branch7x7_3.bn.weight True\n",
            "branch7x7_3.bn.bias True\n",
            "branch7x7dbl_1.conv.weight True\n",
            "branch7x7dbl_1.bn.weight True\n",
            "branch7x7dbl_1.bn.bias True\n",
            "branch7x7dbl_2.conv.weight True\n",
            "branch7x7dbl_2.bn.weight True\n",
            "branch7x7dbl_2.bn.bias True\n",
            "branch7x7dbl_3.conv.weight True\n",
            "branch7x7dbl_3.bn.weight True\n",
            "branch7x7dbl_3.bn.bias True\n",
            "branch7x7dbl_4.conv.weight True\n",
            "branch7x7dbl_4.bn.weight True\n",
            "branch7x7dbl_4.bn.bias True\n",
            "branch7x7dbl_5.conv.weight True\n",
            "branch7x7dbl_5.bn.weight True\n",
            "branch7x7dbl_5.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch7x7_1.conv.weight True\n",
            "branch7x7_1.bn.weight True\n",
            "branch7x7_1.bn.bias True\n",
            "branch7x7_2.conv.weight True\n",
            "branch7x7_2.bn.weight True\n",
            "branch7x7_2.bn.bias True\n",
            "branch7x7_3.conv.weight True\n",
            "branch7x7_3.bn.weight True\n",
            "branch7x7_3.bn.bias True\n",
            "branch7x7dbl_1.conv.weight True\n",
            "branch7x7dbl_1.bn.weight True\n",
            "branch7x7dbl_1.bn.bias True\n",
            "branch7x7dbl_2.conv.weight True\n",
            "branch7x7dbl_2.bn.weight True\n",
            "branch7x7dbl_2.bn.bias True\n",
            "branch7x7dbl_3.conv.weight True\n",
            "branch7x7dbl_3.bn.weight True\n",
            "branch7x7dbl_3.bn.bias True\n",
            "branch7x7dbl_4.conv.weight True\n",
            "branch7x7dbl_4.bn.weight True\n",
            "branch7x7dbl_4.bn.bias True\n",
            "branch7x7dbl_5.conv.weight True\n",
            "branch7x7dbl_5.bn.weight True\n",
            "branch7x7dbl_5.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "conv0.conv.weight True\n",
            "conv0.bn.weight True\n",
            "conv0.bn.bias True\n",
            "conv1.conv.weight True\n",
            "conv1.bn.weight True\n",
            "conv1.bn.bias True\n",
            "fc.weight True\n",
            "fc.bias True\n",
            "branch3x3_1.conv.weight True\n",
            "branch3x3_1.bn.weight True\n",
            "branch3x3_1.bn.bias True\n",
            "branch3x3_2.conv.weight True\n",
            "branch3x3_2.bn.weight True\n",
            "branch3x3_2.bn.bias True\n",
            "branch7x7x3_1.conv.weight True\n",
            "branch7x7x3_1.bn.weight True\n",
            "branch7x7x3_1.bn.bias True\n",
            "branch7x7x3_2.conv.weight True\n",
            "branch7x7x3_2.bn.weight True\n",
            "branch7x7x3_2.bn.bias True\n",
            "branch7x7x3_3.conv.weight True\n",
            "branch7x7x3_3.bn.weight True\n",
            "branch7x7x3_3.bn.bias True\n",
            "branch7x7x3_4.conv.weight True\n",
            "branch7x7x3_4.bn.weight True\n",
            "branch7x7x3_4.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch3x3_1.conv.weight True\n",
            "branch3x3_1.bn.weight True\n",
            "branch3x3_1.bn.bias True\n",
            "branch3x3_2a.conv.weight True\n",
            "branch3x3_2a.bn.weight True\n",
            "branch3x3_2a.bn.bias True\n",
            "branch3x3_2b.conv.weight True\n",
            "branch3x3_2b.bn.weight True\n",
            "branch3x3_2b.bn.bias True\n",
            "branch3x3dbl_1.conv.weight True\n",
            "branch3x3dbl_1.bn.weight True\n",
            "branch3x3dbl_1.bn.bias True\n",
            "branch3x3dbl_2.conv.weight True\n",
            "branch3x3dbl_2.bn.weight True\n",
            "branch3x3dbl_2.bn.bias True\n",
            "branch3x3dbl_3a.conv.weight True\n",
            "branch3x3dbl_3a.bn.weight True\n",
            "branch3x3dbl_3a.bn.bias True\n",
            "branch3x3dbl_3b.conv.weight True\n",
            "branch3x3dbl_3b.bn.weight True\n",
            "branch3x3dbl_3b.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "branch1x1.conv.weight True\n",
            "branch1x1.bn.weight True\n",
            "branch1x1.bn.bias True\n",
            "branch3x3_1.conv.weight True\n",
            "branch3x3_1.bn.weight True\n",
            "branch3x3_1.bn.bias True\n",
            "branch3x3_2a.conv.weight True\n",
            "branch3x3_2a.bn.weight True\n",
            "branch3x3_2a.bn.bias True\n",
            "branch3x3_2b.conv.weight True\n",
            "branch3x3_2b.bn.weight True\n",
            "branch3x3_2b.bn.bias True\n",
            "branch3x3dbl_1.conv.weight True\n",
            "branch3x3dbl_1.bn.weight True\n",
            "branch3x3dbl_1.bn.bias True\n",
            "branch3x3dbl_2.conv.weight True\n",
            "branch3x3dbl_2.bn.weight True\n",
            "branch3x3dbl_2.bn.bias True\n",
            "branch3x3dbl_3a.conv.weight True\n",
            "branch3x3dbl_3a.bn.weight True\n",
            "branch3x3dbl_3a.bn.bias True\n",
            "branch3x3dbl_3b.conv.weight True\n",
            "branch3x3dbl_3b.bn.weight True\n",
            "branch3x3dbl_3b.bn.bias True\n",
            "branch_pool.conv.weight True\n",
            "branch_pool.bn.weight True\n",
            "branch_pool.bn.bias True\n",
            "weight True\n",
            "bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tofhv5UM5zY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a528ff80-f0c8-4dc2-a3fc-dad9a11fdc72"
      },
      "cell_type": "code",
      "source": [
        "# 이 방법이 괜히 귀찮게 2번 하는거면...>! \n",
        "#더 깔끔하게 원하는 Layer 까지만 freeze 하기 \n",
        "child_counter = 0\n",
        "for child in inception.children():\n",
        "    if child_counter < 6:\n",
        "        print(\"child \",child_counter,\" was frozen\")\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "    elif child_counter == 6:\n",
        "        children_of_child_counter = 0\n",
        "        for children_of_child in child.children():\n",
        "            if children_of_child_counter < 1:\n",
        "                for param in children_of_child.parameters():\n",
        "                    param.requires_grad = False\n",
        "                print('child ', children_of_child_counter, 'of child',child_counter,' was frozen')\n",
        "            else:\n",
        "                print('child ', children_of_child_counter, 'of child',child_counter,' was not frozen')\n",
        "            children_of_child_counter += 1\n",
        "\n",
        "    else:\n",
        "        print(\"child \",child_counter,\" was not frozen\")\n",
        "    child_counter += 1\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "child  0  was frozen\n",
            "child  1  was frozen\n",
            "child  2  was frozen\n",
            "child  3  was frozen\n",
            "child  4  was frozen\n",
            "child  5  was frozen\n",
            "child  0 of child 6  was frozen\n",
            "child  1 of child 6  was not frozen\n",
            "child  2 of child 6  was not frozen\n",
            "child  3 of child 6  was not frozen\n",
            "child  4 of child 6  was not frozen\n",
            "child  5 of child 6  was not frozen\n",
            "child  6 of child 6  was not frozen\n",
            "child  7  was not frozen\n",
            "child  8  was not frozen\n",
            "child  9  was not frozen\n",
            "child  10  was not frozen\n",
            "child  11  was not frozen\n",
            "child  12  was not frozen\n",
            "child  13  was not frozen\n",
            "child  14  was not frozen\n",
            "child  15  was not frozen\n",
            "child  16  was not frozen\n",
            "child  17  was not frozen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Db_TvaPB6C3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Pretrained Model 을 사용한 단순한 예시 - End to End \n",
        "## Loading the dataloaders -- Make sure that the data is saved in following way\n",
        "\"\"\"\n",
        "data/\n",
        "  - train/\n",
        "      - class_1 folder/\n",
        "          - img1.png\n",
        "          - img2.png\n",
        "      - class_2 folder/\n",
        "      .....\n",
        "      - class_n folder/\n",
        "  - val/\n",
        "      - class_1 folder/\n",
        "      - class_2 folder/\n",
        "      ......\n",
        "      - class_n folder/\n",
        "\"\"\"\n",
        "\n",
        "data_dir = \"data/\"\n",
        "input_shape = 299\n",
        "batch_size = 32\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "scale = 360\n",
        "input_shape = 299 \n",
        "use_parallel = True\n",
        "use_gpu = True\n",
        "epochs = 100\n",
        "\n",
        "data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "        transforms.Resize(scale),\n",
        "        transforms.RandomResizedCrop(input_shape),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(degrees=90),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)]),\n",
        "        'val': transforms.Compose([\n",
        "        transforms.Resize(scale),\n",
        "        transforms.CenterCrop(input_shape),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)]),}\n",
        "\n",
        "\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                      data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "if use_parallel:\n",
        "    print(\"[Using all the available GPUs]\")\n",
        "    model_conv = nn.DataParallel(model_conv, device_ids=[0, 1])\n",
        "\n",
        "print(\"[Using CrossEntropyLoss...]\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"[Using small learning rate with momentum...]\")\n",
        "optimizer_conv = optim.SGD(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=0.001, momentum=0.9)\n",
        "\n",
        "print(\"[Creating Learning rate scheduler...]\")\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "print(\"[Training the model begun ....]\")\n",
        "# train_model function is here: https://github.com/Prakashvanapalli/pytorch_classifiers/blob/master/tars/tars_training.py\n",
        "model_ft = train_model(model_conv, dataloaders, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, use_gpu,\n",
        "                     num_epochs=epochs)\n",
        "\n",
        "\n",
        "\n",
        "# More in \n",
        "# https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial/blob/master/main_fine_tuning.py \n",
        "# https://github.com/pytorch/tutorials/blob/master/beginner_source/transfer_learning_tutorial.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WnWdisdB6Jfi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 특정한 Layer 의 weight/ bias 만 가져다가 쓰고 싶을 떄?\n"
      ]
    },
    {
      "metadata": {
        "id": "yEqDQFso6GAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_enc.linear_3d.weight = model_trained.linear_3d.weight\n",
        "model_enc.linear_3d.bias = model_trained.linear_3d.bias\n",
        "#이런식으로 그냥 가져다가 쓰면 된다 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzX5N-A-6SHZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  Parameter 자체가 어떻게 생겼는지 보고 싶다면"
      ]
    },
    {
      "metadata": {
        "id": "TjQ-0Fbf6Rma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for child in model.children():\n",
        "    for param in child.parameters():\n",
        "        print(\"Parameters: \",param)\n",
        "        break\n",
        "    break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q308jmip6aFr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 중요!!!! freeze 를 했으면 optimizer를 바꿔줘야 한다 \n",
        "원래는 \n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "이런식으로 model.parameters() 를 다 해줬겠지만,  \n",
        "우리가 freeze 를 시켰기 때문에 error 가 날 것이다 \n"
      ]
    },
    {
      "metadata": {
        "id": "J9OBNsp66bvy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bitr0QbW6cVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 모델 저장하기 \n",
        "pytorch 에서 추천하는 방법으로는 \n",
        "\"state dictionaries\" 방법이다 (빠르고 차지하는 용량도 적음 )\n",
        " - 모델이 어떻게 생겼는지에대한 정보는 하나도 없고 \n",
        " - 그냥 Parameter/weight 의 값만 저장하는 것임 \n",
        " - 나중에 로딩 할 때 똑같은 structure 의 모델을 만들고 loading을 해야한다 \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "OAWAuIBj6gi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MODEL_PATH로 저장한다고 할 때 \n",
        "\n",
        "# Saving a Model\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "\n",
        "# Loading the model.\n",
        "\n",
        "# First create a model and define it's architecture as done above in this notebook. If you want a custom architecture.\n",
        "# read below it's been covered below.\n",
        "checkpoint = torch.load(MODEL_PATH)\n",
        "model.load_state_dict(checkpoint)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8diBVI26iCw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 마지막 layer, 혹은 뒤에서 몇번째 layer만 지우려고 할 때는 위에서 했던것 처럼 걍 지우면 됨\n",
        "왜 이런일을 할까? \n",
        "- classifier가 아니라 feature 를 필요로 할 때 쓴다 "
      ]
    },
    {
      "metadata": {
        "id": "LxVuImK46jiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_model = nn.Sequential(*list(model.children())[:-1])\n",
        "new_model_2_removed = nn.Sequential(*list(model.children())[:-2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lb5SuOAE6ktM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layer 더하기 \n",
        "원래 모델과 똑같은 structure 가 아니라 뒤에 그냥 우리가 원하는 Layer 를 붙이려고 할 때는? \n",
        "- 리스트로 만든 다음에 append 하는 방법--> 보통을 할 수가 없는게, 위에서 얘기 한 것 처럼 loading 할 때 저장했던 '똑같은 ' structure/architecture 의 layer 로 불러 와야해서 list를 쓸 수가 없음 \n",
        "- Adding layers on top - \n",
        "- 단순하게 custom 모델을 만들면 됨 \n",
        "\n",
        "### Custom Models! \n",
        "- 모델의 앞에 반은 pretrained \n",
        "- 모델의 뒤에 반은 새로운거! \n",
        "- 몇개는 freeze 하고 싶고, 몇개는 update 될 수 있게 하고싶다 \n",
        "\n",
        " Segnet에서 써야하는 방법임 - 예시로 resnet 18을 써볼 것"
      ]
    },
    {
      "metadata": {
        "id": "dkcolsdh6nIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "#새로운 모델은 하나의 class로 정의하기!!! \n",
        "#모델을 만든다는건 이 class 의 하나의 instance 를 만드는 것임 \n",
        "\n",
        "\n",
        "#모델 structure: 반은 resent (반만 freeze 시킬 것임)\n",
        "                                    #항상 nn.Module 을 inherit 시키게 하기 \n",
        "class Resnet_Added_Layers_Half_Frozen(nn.Module):\n",
        "    def __init__(self,LOAD_VIS_URL=None):\n",
        "        super(Resnet_Added_Layers_Half_Frozen, self).__init__()\n",
        "    \n",
        "    #앞의 1/2 은 resnet 임 - pretrained 는 false 로 불러오고 원하는 갯수의 class 로 맞춰주기 \n",
        "        model = models.resnet18(pretrained = False)\n",
        "        num_final_in = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_final_in, 300)\n",
        "        \n",
        "        # Architecture 가 똑같으니 이제 weight/parameter를 불러올 수 있음 \n",
        "        checkpoint = torch.load(MODEL_PATH)\n",
        "        model.load_state_dict(checkpoint)\n",
        "        \n",
        "      #몇개 layer 만 Freeze 하기 (여기서는 앞에 6개 layer 만 )\n",
        "        child_counter = 0\n",
        "        for child in model.children():\n",
        "            if child_counter < 6:\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = False\n",
        "            elif child_counter == 6:\n",
        "                children_of_child_counter = 0\n",
        "                for children_of_child in child.children():\n",
        "                    if children_of_child_counter < 1:\n",
        "                        for param in children_of_child.parameters():\n",
        "                            param.requires_grad = False\n",
        "                    else:\n",
        "                    children_of_child_counter += 1\n",
        "\n",
        "            else:\n",
        "                print(\"child \",child_counter,\" was not frozen\")\n",
        "            child_counter += 1\n",
        "        \n",
        "        # 반 정도는 freeze 된 layer들 위에 내가 원하는 새로운 layer 들을 넣는다 \n",
        "        # 가지고 있는 structure 위에 layer 를 더 더한다는 것은 'forward()'로 정의된다 \n",
        "\n",
        "        #self 안에 있어야 함 \n",
        "        self.vismodel = nn.Sequential(*list(model.children()))\n",
        "        self.projective = nn.Linear(512,400)\n",
        "        self.nonlinearity = nn.ReLU(inplace=True)\n",
        "        self.projective2 = nn.Linear(400,300)\n",
        "        \n",
        "    #실제로 모델을 만드는 단계 (input 을 flowㄹ)\n",
        "    def forward(self,x):\n",
        "        x = self.vismodel(x)\n",
        "        x = torch.squeeze(x)\n",
        "        x = self.projective(x)\n",
        "        x = self.nonlinearity(x)\n",
        "        x = self.projective2(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZjBqjzU6qHq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Custom Model \n",
        "- Loss function: 우리가 원하는 결과로부터 얼마나 떨어져 있는지 (얼마나 틀린지를) 수치화한 값\n",
        "- optimizer: parameter들을 어떻게 업데이트 할것인가? (minimize loss 하기 위해서 )\n",
        "\n",
        "Custom loss function 도 class를 써서 만들어야 함 - torch.nn.Module에서  inherit 된다 \n",
        "- 보통 input의 dimension 을 바꿔줘야 할 것임 - view() 함수를 통해서 함 \n",
        "- dimension 을 늘리고 싶으면 unsqueeze() 를 쓴다 \n",
        "- Loss function 을 통과해서 나오는 최종값은 항상 SCALAR 여야 한다 (vector / tensor XXXX)\n",
        "- paramter는 계속 업데이트 되기 때문에 variable 로 만들어줘야 한다 (x, y 둘다 variable  로 정의하기 ) - pytorch tensor 로 정의하기 \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "TKAXGpWZ6smc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "custom loss function - \n",
        "- X: (5, 10)의 형태 \n",
        "- Y: (5, 5, 10 )의 형태 \n",
        "- x 에 dimension 을 더하고, 그 더해진 y 의 dimension 에 맞춰서 반복해야함 \n",
        "- (x - y )의 값은 (5, 5, 10) 모양이 될 것 \n",
        "- scalar로 return 하기 위해서 torch.sum() 을 3번 사용하기 \n"
      ]
    },
    {
      "metadata": {
        "id": "IlaEKq1h6nOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Regress_Loss(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Regress_Loss,self).__init__()\n",
        "        \n",
        "    def forward(self,x,y):\n",
        "        y_shape = y.size()[1]\n",
        "        x_added_dim = x.unsqueeze(1)\n",
        "        x_stacked_along_dimension1 = x_added_dim.repeat(1,NUM_WORDS,1)\n",
        "        diff = torch.sum((y - x_stacked_along_dimension1)**2,2)\n",
        "        totloss = torch.sum(torch.sum(torch.sum(diff)))\n",
        "        return totloss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0995dSh6ukq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save model parameters and loading!!!\n"
      ]
    },
    {
      "metadata": {
        "id": "1kMymVw96xkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  model = MyModel()\n",
        "  # ... after training, save your model \n",
        "  model.save_state_dict('mytraining.pt')\n",
        "\n",
        "  # .. to load your previously training model:\n",
        "  model.load_state_dict(torch.load('mytraining.pt'))\n",
        "pretrained_dict = ...\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# 1. filter out unnecessary keys\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "# 2. overwrite entries in the existing state dict\n",
        "model_dict.update(pretrained_dict) \n",
        "# 3. load the new state dict\n",
        "model.load_state_dict(model_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UEiO-m4l6y94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pre_trained_model=torch.load(\"Path to the .pth file\")\n",
        " new=list(pre_trained.items())\n",
        "\n",
        "my_model_kvpair=mymodel.state_dict()\n",
        "count=0\n",
        "for key,value in my_model_kvpair.item():\n",
        "  layer_name,weights=new[count]      \n",
        "mymodel_kvpair[key]=weights\n",
        "count+=1\n",
        "2\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}